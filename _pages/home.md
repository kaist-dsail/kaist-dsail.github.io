---
title: "DSAIL @ KAIST - Home"
layout: homelay
excerpt: "DSAIL @ KAIST - Home"
sitemap: false
permalink: /
---

<img src="{{ site.url }}{{ site.baseurl }}/images/logopic/dsail_logo2.png" alt="DSAIL character" width ="100%" />

## Welcome!
We are <b>Data Science & Artificial Intelligence Lab (DSAIL) at KAIST</b> led by [Prof. Chanyoung Park](https://kaist-dsail.github.io/professor/){:target="_blank"}. 
Due to the recent expansion of social media and online communities, online platforms in the digital economy are inundated with vast amounts of usergenerated multimodal (heterogeneous) data from various sources, which can be categorized into structured (e.g., graphs such as social network) and unstructured data (e.g., text, image, video, and audio). When properly analyzed, such multimodal data can be a valuable asset to the companies, but it is challenging not only due to the difficulty in
extracting meaningful information from the inherently <em>sparse and noisy data</em>, but also in <em>combining and customizing the extracted knowledge from different modalities with different statistical properties</em> to facilitate various target applications. 

<iframe width="100%" height="315" src="https://www.youtube.com/embed/vV_tNynSJg0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Research Area
Our goal is to <em><b>mine meaningful knowledge from multimodal data, and develop artificial intelligence solutions for various real-world applications across different disciplines.</b></em> 
Two underlying themes of our research are:
1. <em>Representation</em>: How can we extract knowledge from different modalities of data and represent them in a unified way such that the relations among different modalities are captured, and the synergy within the multimodality is facilitated?
2. <em>Fusion</em>: How can we combine the extracted knowledge and customize it to facilitate various underlying target applications?

Our main research interests include <b>Data-centric AI, Machine Learning, Deep Learning, Multi-modal Data Mining</b>, and their applications including but not limited to the following:
- Recommender system
- AI for Science (Chemistry/Bioinformatics/Materials Science)
- Graph Neural Network and its Applications
- Molecular design and Drug discovery
- (Multi-modal) Representation learning
- Large Language Models
- Explainable AI
- Robust machine learning
- Scene understanding
- Knowledge graphs
- Continual learning
- Causal learning
- Social network analysis
- Graph mining
- Fraud/Anomaly detection
- Sentiment analysis
- Purchase/Click prediction
- Time-series and spatio-temporal analysis, 
- AI for finance
- etc...

<div class="carousel-inner" role="listbox" style="width:100%; height: 600px !important;">
<!-- <div class="carousel-inner" role="listbox" style="width:100%; height: 400px !important;">  -->
<div markdown="0" id="carousel" class="carousel slide carousel-fade" data-ride="carousel">
        <!-- Menu -->
        <ol class="carousel-indicators">
            <li data-target="#carousel" data-slide-to="0" class="active"></li>
            <li data-target="#carousel" data-slide-to="1"></li>
            <li data-target="#carousel" data-slide-to="2"></li>
            <!-- Add more indicators for additional slides -->
        </ol>
        <div class="carousel-inner" markdown="0">
            
            <div class="item active">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/NeurIPS24_RetrievalRetro.png" alt="Slide 1" /><br>
                <center><b>Retrieval-Retro: Retrieval-based Inorganic Retrosynthesis with Expert Knowledge, NeurIPS24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/CIKM24_AMOLE.png" alt="" /><br>
                <center><b>Vision Language Model is NOT All You Need: Augmentation Strategies for Molecule Language Models, CIKM24</b></center>
            </div>
            
            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/ECCV24_DPL.png" alt="" /><br>
                <center><b>Semantic Diversity-aware Prototype-based Learning for Unbiased Scene Graph Generation, ECCV24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/ECCV24_Mew.png" alt="" /><br>
                <center><b>Mew: Multiplexed Immunofluorescence Image Analysis through an Efficient Multiplex Network, ECCV24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/KDD24_ALLMRec.png" alt="" /><br>
                <center><b>Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender System, KDD24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/KDD24_TGIB.png" alt="" /><br>
                <center><b>Self-Explainable Temporal Graph Networks based on Graph Information Bottleneck, KDD24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/ICML_NaQ.png" alt="" /><br>
                <center><b>Unsupervised Episode Generation for Graph Meta-learning, ICML24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/CVPR24_LLM4SGG.png" alt="" /><br>
                <center><b>LLM4SGG: Large Language Models for Weakly Supervised Scene Graph Generation, CVPR24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/WWW24_SGGSR.png" alt="" /><br>
                <center><b>Self-guided Robust Graph Structure Refinement, WWW24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/WWW24_DSLR.png" alt="" /><br>
                <center><b>DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning, WWW24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/ICLR24_STSGG.png" alt="" /><br>
                <center><b>Adaptive Self-training Framework for Fine-grained Scene Graph Generation, ICLR24</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/CIKM23_MUSE.png" alt="" /><br>
                <center><b>MUSE&#58; Music Recommender System with Shuffle Play Recommendation Enhancement , CIKM23</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/KDD23_TEG.png" alt="" /><br>
                <center><b>Task-Equivariant Graph Few-shot Learning , KDD23</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/bioinform23_scgpcl.png" alt="" /><br>
                <center><b>Deep single-cell RNA-seq data clustering with graph prototypical contrastive learning, Bioinformatics (2023)</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/CIKM22_LTE4G.png" alt="" /><br>
                <center><b>LTE4G: Long-Tail Experts for Graph Neural Networks, CIKM22</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/CIKM22_RGRL.png" alt="" /><br>
                <center><b>Relational Self-Supervised Learning on Graphs, CIKM22</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/SIGIR22_GraFN.png" alt="" /><br>
                <center><b>GraFN: Semi-Supervised Node Classification on Graph with Few Labels via Non-Parametric Distribution Assignment, SIGIR22</b></center>
            </div>
        
            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/AAAI22.png" alt="" /><br>
                <center><b>Augmentation-Free Self-Supervised Learning on Graphs, AAAI22</b></center>
            </div>
            
            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/KDD20.png" alt="" /><br>
                <center><b>Multi-aspect Network Embedding, KDD20</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/AAAI20.png" alt="" /><br>
                <center><b>Multiplex Network Embedding, AAAI20</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/CIKM19.png" alt="" /><br>
                <center><b>Pair embedding in Heterogeneous Network, CIKM19</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/IJCAI19_1.png" alt="" /><br>
                <center><b>Heterogeneous User Behavior Prediction, IJCAI19</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/IJCAI19_2.png" alt="" /><br>
                <center><b>Sequential and Diverse Recommendation, IJCAI19</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/ICDM18.png" alt="" /><br>
                <center><b>Translation-based Recommendation, ICDM18</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/SIGIR18.png" alt="" /><br>
                <center><b>Sentiment-based Recommendation, SIGIR18</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/WWW17.png" alt="" /><br>
                <center><b>Visual Matrix Co-Factorization, WWW17</b></center>
            </div>

            <div class="item">
                <img src="{{ site.url }}{{ site.baseurl }}/images/slider/RecSys16.png" alt="" /><br>
                <center><b>Convolutional Matrix Factorization, RecSys16</b></center>
            </div>

        <a class="left carousel-control" href="#carousel" role="button" data-slide="prev">
            <span class="glyphicon glyphicon-chevron-left" aria-hidden="true" style="color:DarkGrey"></span>
            <span class="sr-only">Previous</span>
        </a>
        <a class="right carousel-control" href="#carousel" role="button" data-slide="next">
            <span class="glyphicon glyphicon-chevron-right" aria-hidden="true" style="color:DarkGrey"></span>
            <span class="sr-only">Next</span>
        </a>
</div>
</div>



## Interested?
If you’re interested in joining our lab, send an email with your interests, CV, and transcript to cy.park (at) kaist.ac.kr.